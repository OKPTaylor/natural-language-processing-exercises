{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import nltk\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/olivertaylor/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean up the article text\n",
    "def basic_clean(article):\n",
    "    article = article.lower()\n",
    "    article = unicodedata.normalize('NFKD', article).encode('ascii', 'ignore').decode('utf-8', 'ignore') #normalize unicode, get rid of weird characters, and then re-encode (turn back into string)\n",
    "    article = re.sub(r\"[^a-z0-9'\\s]\", '', article)\n",
    "    return article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to tokenize the article\n",
    "def tokenize(article):\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer() # Create tokenizer\n",
    "    article = tokenizer.tokenize(article, return_str=True) # Use tokenizer\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to stem the words in the article\n",
    "def stem(article):\n",
    "    ps = nltk.porter.PorterStemmer() # Create stemmer\n",
    "    stems = [ps.stem(word) for word in article.split()] # loops to Stem each word in the article after splitting\n",
    "    article_stemmed = ' '.join(stems) # joins the stemmed words back into a string\n",
    "    return article_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    \n",
    "    wnl = nltk.stem.WordNetLemmatizer() #creating my lemmatizer\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()] #splitting my string into words and applying the lemma\n",
    "    string = ' '.join(lemmas) #joining back into one string\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove stopwords\n",
    "def remove_stopwords(article, extra_words=[], exclude_words=[]):\n",
    "    # Tokenize the article\n",
    "    article = tokenize(article)\n",
    "    words = article.split()\n",
    "    stopword_list = nltk.corpus.stopwords.words('english')\n",
    "    # Remove the excluded words from the stopword list\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    # Add in the user specified extra words\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    filtered_words = [w for w in words if w not in stopword_list]\n",
    "    article_without_stopwords = ' '.join(filtered_words)\n",
    "    return article_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_list= ['business', 'sports', 'technology', 'entertainment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get article\n",
    "articles = acquire.get_news_articles(topics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Sreenivasa, who worked at Microsoft &amp; Apple, t...</td>\n",
       "      <td>Google is set to appoint Sreenivasa Reddy as i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>What is 'Threads', Meta's Twitter rival?</td>\n",
       "      <td>Mark Zuckerberg-led Meta is set to launch 'Thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>China curbs export of key computer chip materials</td>\n",
       "      <td>China has imposed curbs on exports of some pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>World's first ammonia-powered car engine unvei...</td>\n",
       "      <td>China's state-owned automobile manufacturer GA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Green chilli prices soar to ₹400/kg</td>\n",
       "      <td>The prices of green chilli and ginger have soa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>CBFC orders 21 cuts in Diljit, Arjun Rampal's ...</td>\n",
       "      <td>CBFC has reportedly granted A certificate and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>K3G and DDLJ have spoilt Karwa Chauth for men...</td>\n",
       "      <td>Kajol said that Kabhi Khushi Kabhie Gham and D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>Was tired but satisfied: Alia on doing 'Tum......</td>\n",
       "      <td>Alia Bhatt, when asked about her experience of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>Neetu Kapoor shares childhood pic of Kareena, ...</td>\n",
       "      <td>Actress Neetu Kapoor took to Instagram to shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>Because I'm honest: Shehnaaz Gill on why she t...</td>\n",
       "      <td>Actress and 'Bigg Boss 13' fame Shehnaaz Gill ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                              title  \\\n",
       "0        business  Sreenivasa, who worked at Microsoft & Apple, t...   \n",
       "1        business           What is 'Threads', Meta's Twitter rival?   \n",
       "2        business  China curbs export of key computer chip materials   \n",
       "3        business  World's first ammonia-powered car engine unvei...   \n",
       "4        business                Green chilli prices soar to ₹400/kg   \n",
       "..            ...                                                ...   \n",
       "94  entertainment  CBFC orders 21 cuts in Diljit, Arjun Rampal's ...   \n",
       "95  entertainment   K3G and DDLJ have spoilt Karwa Chauth for men...   \n",
       "96  entertainment  Was tired but satisfied: Alia on doing 'Tum......   \n",
       "97  entertainment  Neetu Kapoor shares childhood pic of Kareena, ...   \n",
       "98  entertainment  Because I'm honest: Shehnaaz Gill on why she t...   \n",
       "\n",
       "                                              content  \n",
       "0   Google is set to appoint Sreenivasa Reddy as i...  \n",
       "1   Mark Zuckerberg-led Meta is set to launch 'Thr...  \n",
       "2   China has imposed curbs on exports of some pro...  \n",
       "3   China's state-owned automobile manufacturer GA...  \n",
       "4   The prices of green chilli and ginger have soa...  \n",
       "..                                                ...  \n",
       "94  CBFC has reportedly granted A certificate and ...  \n",
       "95  Kajol said that Kabhi Khushi Kabhie Gham and D...  \n",
       "96  Alia Bhatt, when asked about her experience of...  \n",
       "97  Actress Neetu Kapoor took to Instagram to shar...  \n",
       "98  Actress and 'Bigg Boss 13' fame Shehnaaz Gill ...  \n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change into a dataframe\n",
    "news_df = pd.DataFrame(articles)\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogs = acquire.get_blog_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>date_published</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spotlight on APIDA Voices: Celebrating Heritag...</td>\n",
       "      <td>https://codeup.com/featured/apida-heritage-month/</td>\n",
       "      <td>May 24, 2023</td>\n",
       "      <td>\\nMay is traditionally known as Asian American...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena ...</td>\n",
       "      <td>https://codeup.com/featured/women-in-tech-pane...</td>\n",
       "      <td>Mar 28, 2023</td>\n",
       "      <td>\\nWomen in tech: Panelist Spotlight – Magdalen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Women in tech: Panelist Spotlight – Rachel Rob...</td>\n",
       "      <td>https://codeup.com/featured/women-in-tech-rach...</td>\n",
       "      <td>Mar 20, 2023</td>\n",
       "      <td>\\nWomen in tech: Panelist Spotlight – Rachel R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Women in Tech: Panelist Spotlight – Sarah Mellor</td>\n",
       "      <td>https://codeup.com/codeup-news/women-in-tech-p...</td>\n",
       "      <td>Mar 13, 2023</td>\n",
       "      <td>\\nWomen in tech: Panelist Spotlight – Sarah Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Women in Tech: Panelist Spotlight – Madeleine ...</td>\n",
       "      <td>https://codeup.com/events/women-in-tech-madele...</td>\n",
       "      <td>Mar 6, 2023</td>\n",
       "      <td>\\nWomen in tech: Panelist Spotlight – Madelein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Black Excellence in Tech: Panelist Spotlight –...</td>\n",
       "      <td>https://codeup.com/codeup-news/panelist-spotli...</td>\n",
       "      <td>Feb 16, 2023</td>\n",
       "      <td>\\nBlack excellence in tech: Panelist Spotlight...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Spotlight on APIDA Voices: Celebrating Heritag...   \n",
       "1  Women in tech: Panelist Spotlight – Magdalena ...   \n",
       "2  Women in tech: Panelist Spotlight – Rachel Rob...   \n",
       "3   Women in Tech: Panelist Spotlight – Sarah Mellor   \n",
       "4  Women in Tech: Panelist Spotlight – Madeleine ...   \n",
       "5  Black Excellence in Tech: Panelist Spotlight –...   \n",
       "\n",
       "                                                link date_published  \\\n",
       "0  https://codeup.com/featured/apida-heritage-month/   May 24, 2023   \n",
       "1  https://codeup.com/featured/women-in-tech-pane...   Mar 28, 2023   \n",
       "2  https://codeup.com/featured/women-in-tech-rach...   Mar 20, 2023   \n",
       "3  https://codeup.com/codeup-news/women-in-tech-p...   Mar 13, 2023   \n",
       "4  https://codeup.com/events/women-in-tech-madele...    Mar 6, 2023   \n",
       "5  https://codeup.com/codeup-news/panelist-spotli...   Feb 16, 2023   \n",
       "\n",
       "                                             content  \n",
       "0  \\nMay is traditionally known as Asian American...  \n",
       "1  \\nWomen in tech: Panelist Spotlight – Magdalen...  \n",
       "2  \\nWomen in tech: Panelist Spotlight – Rachel R...  \n",
       "3  \\nWomen in tech: Panelist Spotlight – Sarah Me...  \n",
       "4  \\nWomen in tech: Panelist Spotlight – Madelein...  \n",
       "5  \\nBlack excellence in tech: Panelist Spotlight...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df = pd.DataFrame(blogs)\n",
    "codeup_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sreenivasa, who worked at Microsoft &amp; Apple, t...</td>\n",
       "      <td>Google is set to appoint Sreenivasa Reddy as i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is 'Threads', Meta's Twitter rival?</td>\n",
       "      <td>Mark Zuckerberg-led Meta is set to launch 'Thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China curbs export of key computer chip materials</td>\n",
       "      <td>China has imposed curbs on exports of some pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World's first ammonia-powered car engine unvei...</td>\n",
       "      <td>China's state-owned automobile manufacturer GA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Green chilli prices soar to ₹400/kg</td>\n",
       "      <td>The prices of green chilli and ginger have soa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Sreenivasa, who worked at Microsoft & Apple, t...   \n",
       "1           What is 'Threads', Meta's Twitter rival?   \n",
       "2  China curbs export of key computer chip materials   \n",
       "3  World's first ammonia-powered car engine unvei...   \n",
       "4                Green chilli prices soar to ₹400/kg   \n",
       "\n",
       "                                            original  \n",
       "0  Google is set to appoint Sreenivasa Reddy as i...  \n",
       "1  Mark Zuckerberg-led Meta is set to launch 'Thr...  \n",
       "2  China has imposed curbs on exports of some pro...  \n",
       "3  China's state-owned automobile manufacturer GA...  \n",
       "4  The prices of green chilli and ginger have soa...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = news_df.rename(columns={'content':'original'}).drop(columns='category')\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['clean'] = news_df.original.apply(basic_clean).apply(tokenize).apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['stem'] = news_df.clean.apply(stem)\n",
    "news_df['lemma'] = news_df.clean.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stem</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sreenivasa, who worked at Microsoft &amp; Apple, t...</td>\n",
       "      <td>Google is set to appoint Sreenivasa Reddy as i...</td>\n",
       "      <td>google set appoint sreenivasa reddy top govern...</td>\n",
       "      <td>googl set appoint sreenivasa reddi top govern ...</td>\n",
       "      <td>google set appoint sreenivasa reddy top govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is 'Threads', Meta's Twitter rival?</td>\n",
       "      <td>Mark Zuckerberg-led Meta is set to launch 'Thr...</td>\n",
       "      <td>mark zuckerbergled meta set launch ' threads '...</td>\n",
       "      <td>mark zuckerbergl meta set launch ' thread ' ju...</td>\n",
       "      <td>mark zuckerbergled meta set launch ' thread ' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China curbs export of key computer chip materials</td>\n",
       "      <td>China has imposed curbs on exports of some pro...</td>\n",
       "      <td>china imposed curbs exports products made gall...</td>\n",
       "      <td>china impos curb export product made gallium g...</td>\n",
       "      <td>china imposed curb export product made gallium...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World's first ammonia-powered car engine unvei...</td>\n",
       "      <td>China's state-owned automobile manufacturer GA...</td>\n",
       "      <td>china ' stateowned automobile manufacturer gac...</td>\n",
       "      <td>china ' stateown automobil manufactur gac said...</td>\n",
       "      <td>china ' stateowned automobile manufacturer gac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Green chilli prices soar to ₹400/kg</td>\n",
       "      <td>The prices of green chilli and ginger have soa...</td>\n",
       "      <td>prices green chilli ginger soared nearly 400 p...</td>\n",
       "      <td>price green chilli ginger soar nearli 400 per ...</td>\n",
       "      <td>price green chilli ginger soared nearly 400 pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>CBFC orders 21 cuts in Diljit, Arjun Rampal's ...</td>\n",
       "      <td>CBFC has reportedly granted A certificate and ...</td>\n",
       "      <td>cbfc reportedly granted certificate ordered 21...</td>\n",
       "      <td>cbfc reportedli grant certif order 21 cut film...</td>\n",
       "      <td>cbfc reportedly granted certificate ordered 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>K3G and DDLJ have spoilt Karwa Chauth for men...</td>\n",
       "      <td>Kajol said that Kabhi Khushi Kabhie Gham and D...</td>\n",
       "      <td>kajol said kabhi khushi kabhie gham dilwale du...</td>\n",
       "      <td>kajol said kabhi khushi kabhi gham dilwal dulh...</td>\n",
       "      <td>kajol said kabhi khushi kabhie gham dilwale du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Was tired but satisfied: Alia on doing 'Tum......</td>\n",
       "      <td>Alia Bhatt, when asked about her experience of...</td>\n",
       "      <td>alia bhatt asked experience shooting ' tum kya...</td>\n",
       "      <td>alia bhatt ask experi shoot ' tum kya mile ' s...</td>\n",
       "      <td>alia bhatt asked experience shooting ' tum kya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Neetu Kapoor shares childhood pic of Kareena, ...</td>\n",
       "      <td>Actress Neetu Kapoor took to Instagram to shar...</td>\n",
       "      <td>actress neetu kapoor took instagram share chil...</td>\n",
       "      <td>actress neetu kapoor took instagram share chil...</td>\n",
       "      <td>actress neetu kapoor took instagram share chil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Because I'm honest: Shehnaaz Gill on why she t...</td>\n",
       "      <td>Actress and 'Bigg Boss 13' fame Shehnaaz Gill ...</td>\n",
       "      <td>actress ' bigg boss 13 ' fame shehnaaz gill as...</td>\n",
       "      <td>actress ' bigg boss 13 ' fame shehnaaz gill as...</td>\n",
       "      <td>actress ' bigg bos 13 ' fame shehnaaz gill ask...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Sreenivasa, who worked at Microsoft & Apple, t...   \n",
       "1            What is 'Threads', Meta's Twitter rival?   \n",
       "2   China curbs export of key computer chip materials   \n",
       "3   World's first ammonia-powered car engine unvei...   \n",
       "4                 Green chilli prices soar to ₹400/kg   \n",
       "..                                                ...   \n",
       "94  CBFC orders 21 cuts in Diljit, Arjun Rampal's ...   \n",
       "95   K3G and DDLJ have spoilt Karwa Chauth for men...   \n",
       "96  Was tired but satisfied: Alia on doing 'Tum......   \n",
       "97  Neetu Kapoor shares childhood pic of Kareena, ...   \n",
       "98  Because I'm honest: Shehnaaz Gill on why she t...   \n",
       "\n",
       "                                             original  \\\n",
       "0   Google is set to appoint Sreenivasa Reddy as i...   \n",
       "1   Mark Zuckerberg-led Meta is set to launch 'Thr...   \n",
       "2   China has imposed curbs on exports of some pro...   \n",
       "3   China's state-owned automobile manufacturer GA...   \n",
       "4   The prices of green chilli and ginger have soa...   \n",
       "..                                                ...   \n",
       "94  CBFC has reportedly granted A certificate and ...   \n",
       "95  Kajol said that Kabhi Khushi Kabhie Gham and D...   \n",
       "96  Alia Bhatt, when asked about her experience of...   \n",
       "97  Actress Neetu Kapoor took to Instagram to shar...   \n",
       "98  Actress and 'Bigg Boss 13' fame Shehnaaz Gill ...   \n",
       "\n",
       "                                                clean  \\\n",
       "0   google set appoint sreenivasa reddy top govern...   \n",
       "1   mark zuckerbergled meta set launch ' threads '...   \n",
       "2   china imposed curbs exports products made gall...   \n",
       "3   china ' stateowned automobile manufacturer gac...   \n",
       "4   prices green chilli ginger soared nearly 400 p...   \n",
       "..                                                ...   \n",
       "94  cbfc reportedly granted certificate ordered 21...   \n",
       "95  kajol said kabhi khushi kabhie gham dilwale du...   \n",
       "96  alia bhatt asked experience shooting ' tum kya...   \n",
       "97  actress neetu kapoor took instagram share chil...   \n",
       "98  actress ' bigg boss 13 ' fame shehnaaz gill as...   \n",
       "\n",
       "                                                 stem  \\\n",
       "0   googl set appoint sreenivasa reddi top govern ...   \n",
       "1   mark zuckerbergl meta set launch ' thread ' ju...   \n",
       "2   china impos curb export product made gallium g...   \n",
       "3   china ' stateown automobil manufactur gac said...   \n",
       "4   price green chilli ginger soar nearli 400 per ...   \n",
       "..                                                ...   \n",
       "94  cbfc reportedli grant certif order 21 cut film...   \n",
       "95  kajol said kabhi khushi kabhi gham dilwal dulh...   \n",
       "96  alia bhatt ask experi shoot ' tum kya mile ' s...   \n",
       "97  actress neetu kapoor took instagram share chil...   \n",
       "98  actress ' bigg boss 13 ' fame shehnaaz gill as...   \n",
       "\n",
       "                                                lemma  \n",
       "0   google set appoint sreenivasa reddy top govern...  \n",
       "1   mark zuckerbergled meta set launch ' thread ' ...  \n",
       "2   china imposed curb export product made gallium...  \n",
       "3   china ' stateowned automobile manufacturer gac...  \n",
       "4   price green chilli ginger soared nearly 400 pe...  \n",
       "..                                                ...  \n",
       "94  cbfc reportedly granted certificate ordered 21...  \n",
       "95  kajol said kabhi khushi kabhie gham dilwale du...  \n",
       "96  alia bhatt asked experience shooting ' tum kya...  \n",
       "97  actress neetu kapoor took instagram share chil...  \n",
       "98  actress ' bigg bos 13 ' fame shehnaaz gill ask...  \n",
       "\n",
       "[99 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
